{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 4\n",
    "batch_size = 1\n",
    "input_dim = 512\n",
    "d_model = 512\n",
    "x = torch.randn((batch_size,sequence_length, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_layer = nn.Linear(input_dim,3 * d_model)\n",
    "qkv = qkv_layer(x)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2017,  1.1068,  0.0260,  ..., -1.1974, -0.5606,  0.9321],\n",
       "         [-0.5236, -0.3487,  0.2872,  ...,  0.4473, -0.2781,  0.8835],\n",
       "         [-1.4264, -0.4598, -0.0927,  ...,  1.1395, -0.9284,  0.0876],\n",
       "         [ 0.9463,  0.1999, -0.7228,  ...,  0.3074, -0.0309, -0.3068]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'qkv distribution')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_val = torch.histc(qkv, bins=200, min=-3, max=3)\n",
    "x_val = np.arange(-1, 1, 0.01) * 3\n",
    "plt.bar(x_val, y_val, align='center', color=['forestgreen'])\n",
    "plt.title('qkv distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads = 8\n",
    "head_dim = d_model // num_heads\n",
    "qkv = qkv.reshape(batch_size , sequence_length , num_heads , 3*head_dim)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv.permute(0, 2, 1, 3) # [batch_size, num_heads, sequence_length, 3*head_dim]\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.chunk(3, dim=-1)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Attention for multiple heads\n",
    "\n",
    "For a single head:\n",
    "$$\n",
    "\\text{self attention} = softmax\\bigg(\\frac{Q.K^T}{\\sqrt{d_k}}+M\\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{new V} = \\text{self attention}.V\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q,k.transpose(-2,-1)) / math.sqrt(d_k)\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 8, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4816, -0.7550, -0.7410],\n",
      "        [-0.2392, -0.5091,  0.7270]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4816, -0.2392],\n",
       "        [-0.7550, -0.5091],\n",
       "        [-0.7410,  0.7270]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(2,3)\n",
    "print(y)\n",
    "torch.transpose(y , 1 , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-1, -2) == k.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 64, 4]), torch.Size([1, 8, 64, 4]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-1, -2).shape , k.transpose(-2, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.size() ,float('-inf'))\n",
    "mask = torch.triu(mask , diagonal=1)\n",
    "print(mask.shape)\n",
    "mask[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2375,    -inf,    -inf,    -inf],\n",
       "        [ 0.3853, -0.0981,    -inf,    -inf],\n",
       "        [-0.2778,  0.4048,  0.5006,    -inf],\n",
       "        [-0.2462,  0.1624, -0.3263,  0.0839]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled += mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6269606805367254"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0.5596) / (np.exp(0.5596) + np.exp(0.0404))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = F.softmax(scaled, dim=-1)\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.6186, 0.3814, 0.0000, 0.0000],\n",
       "        [0.1939, 0.3838, 0.4223, 0.0000],\n",
       "        [0.2075, 0.3122, 0.1915, 0.2887]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention,v)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]), torch.Size([1, 8, 4, 4]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, attention = scaled_dot_product(q, k, v, mask=mask)\n",
    "values.shape, attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.6339, 0.3661, 0.0000, 0.0000],\n",
       "        [0.3593, 0.3458, 0.2949, 0.0000],\n",
       "        [0.2159, 0.2298, 0.2488, 0.3056]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5142e-02, -4.8592e-01, -4.8775e-01, -1.1860e-01, -9.3277e-01,\n",
       "         -1.0998e+00, -1.1298e+00, -9.5773e-02,  5.5119e-01, -5.6895e-01,\n",
       "         -3.6001e-01,  3.7907e-01,  7.7693e-01, -1.5217e-01, -1.1263e+00,\n",
       "          1.9349e-02, -6.3687e-01,  9.7181e-02,  1.5596e-01, -8.0707e-01,\n",
       "          9.7127e-02, -3.0956e-02,  1.2549e+00,  7.2740e-01,  7.1831e-01,\n",
       "          2.1477e-01, -4.7388e-01, -3.2426e-01,  3.3248e-01,  7.0756e-01,\n",
       "          1.7729e-01, -1.0177e+00, -4.3114e-01,  6.7719e-01, -6.1016e-01,\n",
       "          6.5727e-01, -8.5627e-01, -1.3770e+00, -5.6093e-01, -3.7432e-01,\n",
       "         -1.3737e+00,  9.9558e-01,  4.1240e-02, -4.3450e-01, -1.0823e+00,\n",
       "         -6.4076e-01, -4.9675e-01, -7.3843e-01,  4.7464e-01, -9.3642e-01,\n",
       "         -1.1230e+00, -1.2950e-01,  3.2031e-01,  1.8081e-02, -3.8488e-01,\n",
       "          5.3034e-02,  6.4935e-01, -1.5207e-01, -7.4602e-02,  3.4790e-01,\n",
       "         -5.4829e-02,  1.1093e+00, -3.4864e-01,  6.8235e-01],\n",
       "        [-3.6325e-01,  1.8120e-01, -5.9729e-01,  7.6069e-02, -2.2395e-01,\n",
       "         -1.2705e-01, -1.0491e+00,  2.7260e-01,  3.8329e-01,  2.4693e-01,\n",
       "         -1.9626e-01, -2.3017e-01,  1.7763e-01,  4.6800e-02, -5.1042e-01,\n",
       "          7.2135e-02, -6.9705e-01,  3.1385e-01, -1.3238e-01, -1.0721e+00,\n",
       "         -8.3309e-02,  3.5894e-01,  2.1370e-01,  4.2765e-01,  3.5538e-01,\n",
       "          3.8833e-02, -1.0941e-01,  1.3726e-01,  2.4956e-01,  6.9383e-01,\n",
       "          2.4141e-01, -4.1902e-01,  9.2708e-02,  7.3710e-01, -2.0217e-02,\n",
       "          9.2076e-01, -4.9973e-01, -5.7990e-01, -4.5152e-01,  1.3664e-01,\n",
       "         -4.1147e-01,  9.6582e-01, -4.0644e-01,  1.6765e-01, -3.7387e-01,\n",
       "         -6.5489e-01,  1.4582e-01, -1.0564e-01,  1.4029e-01, -9.2274e-01,\n",
       "         -9.1402e-01, -5.4474e-01,  7.7751e-01,  1.5072e-02, -5.1335e-01,\n",
       "         -4.2879e-01,  3.8501e-02,  4.3699e-01, -1.0088e-02,  6.1601e-02,\n",
       "         -1.0284e+00,  6.2837e-01,  3.1167e-01,  3.1683e-02],\n",
       "        [-2.0791e-01, -2.4060e-02, -4.0910e-01, -9.2412e-02,  1.4232e-01,\n",
       "         -3.4682e-02, -4.4624e-01,  2.2446e-01,  3.4986e-01,  3.4776e-02,\n",
       "         -1.2501e-01, -3.2363e-01,  3.2358e-01, -5.9414e-02, -4.5115e-01,\n",
       "          1.6313e-01, -3.6133e-01,  1.4543e-01, -2.7103e-02, -7.8625e-01,\n",
       "         -2.6308e-01,  2.2679e-01,  1.1286e-01,  3.8387e-01,  3.6328e-01,\n",
       "          2.3142e-02,  2.4320e-02, -7.2152e-02,  3.6594e-01,  7.1146e-01,\n",
       "         -1.6463e-01, -2.0905e-01,  2.3305e-02,  6.9507e-01,  1.4836e-01,\n",
       "          5.4603e-01, -2.4533e-01, -5.6065e-01, -5.7784e-01,  9.3165e-02,\n",
       "         -2.6404e-01,  5.2262e-01, -2.4192e-01,  2.1240e-01, -7.6291e-02,\n",
       "         -5.3073e-01, -7.2166e-02, -2.5152e-01,  1.3041e-01, -5.0656e-01,\n",
       "         -6.9349e-01, -2.5553e-01,  6.4564e-01, -6.1798e-02, -3.1531e-01,\n",
       "         -5.7962e-01,  1.6397e-01,  1.5280e-01,  2.5989e-01, -1.4976e-01,\n",
       "         -9.3694e-01,  4.5154e-01,  9.0678e-02, -1.3276e-01],\n",
       "        [-3.0352e-01,  2.6109e-01, -4.5162e-01,  7.4468e-02,  4.0917e-01,\n",
       "          2.0624e-01, -4.8930e-01,  2.5146e-01,  4.5984e-01,  6.4385e-02,\n",
       "          1.0881e-01, -4.6909e-01,  1.7374e-01, -2.1469e-01, -1.3224e-02,\n",
       "          1.5930e-01, -1.8621e-01, -1.0505e-03, -8.8663e-03, -8.5243e-01,\n",
       "         -3.7924e-01,  2.9691e-01, -1.5410e-01,  2.0406e-01,  9.8028e-02,\n",
       "          1.5727e-01,  2.0339e-01, -1.3128e-01,  9.5528e-02,  3.9723e-01,\n",
       "         -1.3202e-01,  4.3297e-02, -2.1796e-02,  5.5488e-01,  1.6642e-01,\n",
       "          4.3201e-01,  1.4180e-01, -2.6447e-01, -2.5650e-01,  1.6790e-01,\n",
       "         -1.4892e-01,  4.6954e-01, -2.9301e-01,  4.5732e-01,  1.9704e-01,\n",
       "         -3.8256e-01,  1.6986e-01, -1.8987e-02, -1.1259e-01, -4.2052e-01,\n",
       "         -4.0023e-01, -3.4819e-01,  6.3846e-01, -2.5227e-03, -4.9193e-02,\n",
       "         -4.3544e-01,  1.3624e-01, -5.3738e-02,  3.9420e-01, -3.8855e-01,\n",
       "         -8.8357e-01,  4.0068e-01,  2.5916e-01, -4.9682e-01]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size, sequence_length, num_heads * head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model,d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = linear_layer(values)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6338, -0.0215, -0.4086,  ..., -0.3895, -0.3378, -0.1123],\n",
       "         [-0.4972,  0.2225,  0.0382,  ...,  0.0462,  0.0242, -0.2343],\n",
       "         [-0.1701, -0.2749,  0.0717,  ..., -0.1998, -0.3026, -0.0630],\n",
       "         [-0.1397,  0.0029, -0.0619,  ..., -0.1025,  0.0604,  0.3012]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# Define the scaled dot product attention function\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    # Get the dimension of the key vectors\n",
    "    d_k = q.size()[-1]\n",
    "    \n",
    "    # Calculate the scaled dot product attention\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    \n",
    "    # Add the mask if provided\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    \n",
    "    # Apply the softmax to obtain attention weights\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    \n",
    "    # Calculate the weighted sum using attention weights\n",
    "    values = torch.matmul(attention, v)\n",
    "    \n",
    "    return values, attention\n",
    "\n",
    "# Define the MultiheadAttention module\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        \n",
    "        # Linear layer for Q, K, V\n",
    "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
    "        \n",
    "        # Linear layer after concatenating the outputs from different heads\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # Get dimensions of the input tensor\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size(): {x.size()}\")\n",
    "        # Linear transformation for Q, K, V\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        \n",
    "        # Reshape the tensor to split into Q, K, V for each head\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "                \n",
    "        # Permute the dimensions for matrix multiplication\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "                \n",
    "        # Split into Q, K, V\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
    "                \n",
    "        # Apply scaled dot product attention\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
    "                \n",
    "        # Reshape values and apply linear transformation\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\")\n",
    "        \n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\")\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64]), \n",
      "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out.size(): torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 30\n",
    "sequence_length = 5\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
    "\n",
    "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
